{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOhktTAKf3ueCZfIhpct19o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DmitryiLaptev/NeuralNetworks_HW/blob/main/%D0%97%D0%B0%D0%B4%D0%B0%D1%87%D0%B0_3%2C_%D0%94_%D0%97_%D0%9D%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D1%8B%D0%B5_%D1%81%D0%B5%D1%82%D0%B8_(%D0%9B%D0%B0%D0%BF%D1%82%D0%B5%D0%B2_%D0%94_%D0%90_)_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задача 3. Автокодировщик** (10 баллов) \n",
        "\n",
        "Провести анализ модели автокодировщика (не вариационного) для [выборки Twitter](https://drive.google.com/drive/folders/1NdhIpkVTDBDyal-KM54XI2GvqOtFbJlD?usp=sharing) (эмбединги предложений). Требуется сравнить качество востановления предложения в зависимости от размера слоя, числа слоев, dropout, BatchNorm, размера словаря. Все выводы должны быть представленны в формате TensorBoard.\n"
      ],
      "metadata": {
        "id": "AKcWnUZyCK-k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2Gsk0jfKXk0"
      },
      "outputs": [],
      "source": [
        "# Загрузка библиотек\n",
        "from copy import deepcopy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.image import imread\n",
        "from mpl_toolkits import mplot3d\n",
        "from matplotlib import gridspec\n",
        "from PIL import Image\n",
        "import io\n",
        "import os\n",
        "from urllib.request import urlopen\n",
        "from skimage.segmentation import mark_boundaries\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "import requests\n",
        "from scipy.stats import norm\n",
        "import torch\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Установка AutoTokenizer и torchmetrics\n",
        "! pip install --quiet transformers\n",
        "! pip install --quiet torchmetrics\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "import torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvkCQpP6LMga",
        "outputId": "f5835fa8-c5ff-47f4-ef45-233f9bfd9e2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m94.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Определим устройство на котором происходят вычисления\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7oltre74Lgn-",
        "outputId": "006f1826-9950-48ba-bfc7-ea1d1d350e9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Выгрузка данных\n",
        "import pandas as pd\n",
        "\n",
        "dataset = pd.read_csv('/content/twitter.csv')\n",
        "dataset = dataset.sample(10000, random_state=42)\n",
        "dataset.sample(10, random_state=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "EwBI-SDVL3l6",
        "outputId": "350bf0a0-1d8a-4c5d-d157-a035edf0358b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         tag                                            message\n",
              "204869   0.0  @gabsramazzina brigadeiro? what are you trying...\n",
              "1406138  0.0  Get the bill of being lazy, and I have no mone...\n",
              "1404132  0.0  Forgot i bought a packet of monster munch earl...\n",
              "751245   1.0  Girls to do the dishes, girls to clean up my r...\n",
              "298055   1.0  @MariKurisato now is back working...what she d...\n",
              "357045   0.0  @notoastmaker baked mac and cheese  it was REA...\n",
              "278687   1.0  @joeymcintyre &quot;suck the nectar&quot; -- t...\n",
              "1538277  0.0  still bored.... very, very, i mean really BORE...\n",
              "437885   1.0   @sky327 Thanks!  I'm a bit hoarse from screaming\n",
              "1364350  1.0  23 days until i'm 10 rows away from dane cook...."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-abdc0763-3afc-4b12-8218-b4f97e78b366\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tag</th>\n",
              "      <th>message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>204869</th>\n",
              "      <td>0.0</td>\n",
              "      <td>@gabsramazzina brigadeiro? what are you trying...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1406138</th>\n",
              "      <td>0.0</td>\n",
              "      <td>Get the bill of being lazy, and I have no mone...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1404132</th>\n",
              "      <td>0.0</td>\n",
              "      <td>Forgot i bought a packet of monster munch earl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>751245</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Girls to do the dishes, girls to clean up my r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298055</th>\n",
              "      <td>1.0</td>\n",
              "      <td>@MariKurisato now is back working...what she d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>357045</th>\n",
              "      <td>0.0</td>\n",
              "      <td>@notoastmaker baked mac and cheese  it was REA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>278687</th>\n",
              "      <td>1.0</td>\n",
              "      <td>@joeymcintyre &amp;quot;suck the nectar&amp;quot; -- t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1538277</th>\n",
              "      <td>0.0</td>\n",
              "      <td>still bored.... very, very, i mean really BORE...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>437885</th>\n",
              "      <td>1.0</td>\n",
              "      <td>@sky327 Thanks!  I'm a bit hoarse from screaming</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1364350</th>\n",
              "      <td>1.0</td>\n",
              "      <td>23 days until i'm 10 rows away from dane cook....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-abdc0763-3afc-4b12-8218-b4f97e78b366')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-abdc0763-3afc-4b12-8218-b4f97e78b366 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-abdc0763-3afc-4b12-8218-b4f97e78b366');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_mask = np.random.rand(len(dataset), ) < 0.8\n",
        "train_ds = dataset[train_mask]\n",
        "val_ds = dataset[~train_mask]\n",
        "\n",
        "train = train_ds['message'].to_list()\n",
        "val   = val_ds['message'].to_list()"
      ],
      "metadata": {
        "id": "m9NVkvUiMuCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Токенизатор\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/LaBSE\", verbose=False)\n",
        "\n",
        "tokenized_train_codes = tokenizer(train, return_tensors='pt', max_length=64, padding=True, truncation=True)['input_ids']\n",
        "tokenized_val_codes   = tokenizer(val,   return_tensors='pt', max_length=64, padding=True, truncation=True)['input_ids']\n",
        "\n",
        "print(f'init size of vocab: {tokenizer.vocab_size}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iapcvv6rMzvD",
        "outputId": "df645e48-8318-4ca6-86db-37e35f9b9b3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "init size of vocab: 501153\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Уменьшим размер словаря\n",
        "new_vocab = {tokenizer.pad_token_id:0, tokenizer.unk_token_id:1}\n",
        "for token in tokenized_train_codes.unique().tolist():\n",
        "  if token not in new_vocab:\n",
        "    new_vocab[token] = len(new_vocab.values())\n",
        "\n",
        "print(f'reduced size of vocab: {len(new_vocab)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLoQvdOENwt0",
        "outputId": "4a554aae-6a57-42be-b0cf-95d21f1b4ec5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reduced size of vocab: 17563\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция tokenize\n",
        "def tokenize(tokenized_data_in_num, new_vocab):\n",
        "  new_tokenized_data = []\n",
        "  for sent in tokenized_data_in_num:\n",
        "    new_tokenized_sentence = []\n",
        "    for num in sent:  \n",
        "      num = int(num)\n",
        "      if num in new_vocab :\n",
        "        new_tokenized_sentence.append(int(new_vocab[num]))\n",
        "      else:\n",
        "        new_tokenized_sentence.append(int(new_vocab[tokenizer.unk_token_id]))\n",
        "    new_tokenized_data.append(new_tokenized_sentence)\n",
        "\n",
        "  return new_tokenized_data"
      ],
      "metadata": {
        "id": "ReBVO6EwXS9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_train = tokenize(tokenized_train_codes, new_vocab)\n",
        "tokenized_val   = tokenize(tokenized_val_codes,   new_vocab)\n",
        "\n",
        "train_ds = torch.utils.data.TensorDataset(torch.tensor(tokenized_train), torch.tensor(tokenized_train))\n",
        "val_ds   = torch.utils.data.TensorDataset(torch.tensor(tokenized_val), torch.tensor(tokenized_val))\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dl = torch.utils.data.DataLoader(train_ds, batch_size = BATCH_SIZE)\n",
        "val_dl   = torch.utils.data.DataLoader(val_ds, batch_size = BATCH_SIZE)"
      ],
      "metadata": {
        "id": "nOePs_JPXefF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция энкодера\n",
        "def encode_sentence(sentence, tokenizer, new_vocab):\n",
        "  tokenized_sentence = tokenizer.encode(sentence)\n",
        "  new_tokenized_sentence = []\n",
        "  for num in tokenized_sentence:  \n",
        "      num = int(num)\n",
        "      if num in new_vocab:\n",
        "        new_tokenized_sentence.append(new_vocab[num])\n",
        "      else:\n",
        "        new_tokenized_sentence.append(new_vocab[tokenizer.unk_token_id])\n",
        "  \n",
        "  return new_tokenized_sentence"
      ],
      "metadata": {
        "id": "PlYqgiF9XpKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция декодера\n",
        "def decode_sentence(tokenized_sentence, tokenizer, new_vocab) :\n",
        "  vocab = dict(map(lambda pair: (pair[1], pair[0]), new_vocab.items()))\n",
        "  old_tokenized_sentence = []\n",
        "  for token in tokenized_sentence:\n",
        "    old_tokenized_sentence.append(vocab[token])\n",
        "\n",
        "  sentence = tokenizer.decode(old_tokenized_sentence)\n",
        "\n",
        "  return sentence"
      ],
      "metadata": {
        "id": "1RjEwKNjXr49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание модели \n",
        "class Encoder(torch.nn.Module):\n",
        "  def __init__(self, vocab_size, emb_dim=30, hidden_dim=30, p=0):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.embedding = torch.nn.Embedding(vocab_size, emb_dim)\n",
        "    self.lstm = torch.nn.LSTM(emb_dim, hidden_dim, batch_first=True, bidirectional=True, dropout=p)\n",
        "\n",
        "  def forward(self, input):\n",
        "    input = self.embedding(input)\n",
        "    out, h_c = self.lstm(input)\n",
        "    return out, h_c"
      ],
      "metadata": {
        "id": "ay3X83iEXwdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание модели \n",
        "class Decoder(torch.nn.Module):\n",
        "  def __init__(self, vocab_size, encoded_dim, hidden_dim=30, p=0):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.lstm = torch.nn.LSTM(encoded_dim, hidden_dim, batch_first=True, bidirectional=True, dropout=p)\n",
        "    self.linear = torch.nn.Linear(2*hidden_dim, vocab_size)\n",
        "    self.dropout = torch.nn.Dropout(p)\n",
        "\n",
        "  def forward(self, encoder_output):\n",
        "    x, h_c = encoder_output\n",
        "    out, h_c = self.lstm(x, h_c)\n",
        "    out = self.dropout(self.linear(out))\n",
        "    return out"
      ],
      "metadata": {
        "id": "ZywBmshpXzA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание модели \n",
        "class AutoEncoder(torch.nn.Module):\n",
        "  def __init__(self, vocab_size, latent_dim=30, emb_dim=30, hidden_dim=30, \n",
        "               num_layers=1, p=0, zero_input=True):\n",
        "    super(AutoEncoder, self).__init__()\n",
        "\n",
        "    self.num_classes = vocab_size\n",
        "    \n",
        "    self.encoder = Encoder(vocab_size, emb_dim, hidden_dim, p)\n",
        "    self.decoder = Decoder(vocab_size, 2*hidden_dim, hidden_dim, p)\n",
        "\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.latent_dim = latent_dim\n",
        "    self.emb_dim = emb_dim\n",
        "    self.num_layers = num_layers\n",
        "    self.dropout = torch.nn.Dropout(p)\n",
        "    self.p = p\n",
        "\n",
        "  def forward(self, input):\n",
        "    encoder_out = self.encoder(input)\n",
        "    decoder_out = self.decoder(encoder_out) \n",
        "    out = decoder_out.transpose(1, 2)\n",
        "    return out"
      ],
      "metadata": {
        "id": "vRWaYKboX2AJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Вычисление точности загрузки данных\n",
        "def calc_accuracy_dl(model, dl, writer, name_dl=None, num_step=0) :\n",
        "  sum_acc = 0\n",
        "  for i, (features, labels) in enumerate(dl):\n",
        "    if i > (BATCH_SIZE * 2) :\n",
        "      break\n",
        "    features = features.to(device)\n",
        "    labels = labels.to(device)\n",
        "    preds = model(features)\n",
        "\n",
        "    sum_acc += torchmetrics.functional.accuracy(preds, labels, task='multiclass', num_classes=model.num_classes, ignore_index=0)\n",
        "\n",
        "  acc = sum_acc / (BATCH_SIZE * 2)\n",
        "  \n",
        "  writer.add_scalars(main_tag = f'{name_dl} accuracy', \n",
        "                     tag_scalar_dict={f'vocab_size = {model.num_classes}, latent_dim={model.latent_dim}, emb_dim={model.emb_dim}, hidden_dim={model.hidden_dim}, num_layers={model.num_layers}, drop_p={model.p},': acc}, \n",
        "                     global_step=num_step)\n",
        "  return acc\n",
        "\n",
        "def calc_all_accuracy(model, num_epoch, epochs, train_dl, val_dl, writer, num_step, dump_p=False) :\n",
        "  train_acc = calc_accuracy_dl(model, train_dl, writer, name_dl='train', num_step=num_step)\n",
        "  val_acc   = calc_accuracy_dl(model, val_dl,   writer, name_dl='valid', num_step=num_step)\n",
        "  if dump_p:\n",
        "    print(f\"[{num_epoch}/{epochs}]: train accuracy = {train_acc}, validation accuracy = {val_acc}\")\n",
        "  return val_acc, train_acc\n",
        "\n",
        "def dump_to_tensorboard(model, num_epoch, val_dl, writer) :\n",
        "  preds = None\n",
        "  labels = None\n",
        "  for i, (features, labels) in enumerate(val_dl):\n",
        "    features = features.to(device)\n",
        "    labels = labels.to(device)\n",
        "    preds = model(features)\n",
        "    break\n",
        "\n",
        "  preds = torch.argmax(preds, 1)[0].cpu().tolist()\n",
        "  targets = labels[0].cpu().tolist()\n",
        "\n",
        "  decoded_prediction = decode_sentence(preds, tokenizer, new_vocab)\n",
        "\n",
        "  writer.add_text(tag=f'val_preds: vocab_size = {model.num_classes}, latent_dim={model.latent_dim}, emb_dim={model.emb_dim}, hidden_dim={model.hidden_dim}, num_layers={model.num_layers}, drop_p={model.p}',\n",
        "                  text_string=decoded_prediction, \n",
        "                  global_step=num_epoch)"
      ],
      "metadata": {
        "id": "XSmMYoziX9QX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучение\n",
        "def train(model, optimizer, train_dl, val_dl, writer, epochs=30, device=device):\n",
        "  model.to(device)\n",
        "\n",
        "  num_step = 0\n",
        "  \n",
        "  calc_all_accuracy(model, 0, epochs, train_dl, val_dl, writer, num_step, dump_p=True)\n",
        "\n",
        "  best_model = model\n",
        "  best_acc = 0\n",
        "  for epoch in range(0, epochs):\n",
        "    model.train()\n",
        "    for i, (features, labels) in enumerate(train_dl): \n",
        "      \n",
        "      num_step = num_step + 1\n",
        "      if (num_step) % (BATCH_SIZE * 2) == 0:\n",
        "          calc_all_accuracy(model, epoch + 1, epochs, train_dl, val_dl, writer, num_step, dump_p=False)\n",
        "\n",
        "      features, labels = features.to(device), labels.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      pred = model(features)\n",
        "      loss = torch.nn.functional.cross_entropy(pred, labels, ignore_index=0)\n",
        "      loss.backward()\n",
        "      \n",
        "      optimizer.step()\n",
        "\n",
        "    val_acc, _ = calc_all_accuracy(model, epoch + 1, epochs, train_dl, val_dl, writer, num_step, dump_p=True)\n",
        "    dump_to_tensorboard(model, epoch + 1, val_dl, writer)\n",
        "\n",
        "    if (val_acc > best_acc):\n",
        "      best_model = deepcopy(model)\n",
        "      best_acc = val_acc\n",
        "  \n",
        "  return best_model"
      ],
      "metadata": {
        "id": "Gea_oi6UYCc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! rm -rf './runs'"
      ],
      "metadata": {
        "id": "Ionhb9ApYFu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer = SummaryWriter()\n",
        "\n",
        "num_layerss = [2, 4]\n",
        "hidden_dims = [200, 400]\n",
        "drop_ps = [0.1, 0.3]\n",
        "\n",
        "for num_layers in num_layerss :\n",
        "  for hidden_dim in hidden_dims :\n",
        "    for drop_p in drop_ps:\n",
        "      print (f'\\n num_layers = {num_layers}, hidden_dim = {hidden_dim}, drop_p = {drop_p}')\n",
        "      model = AutoEncoder(vocab_size=len(new_vocab), latent_dim=30, emb_dim=30, hidden_dim=hidden_dim, \n",
        "                          num_layers=num_layers, p=drop_p, zero_input=True)\n",
        "      optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "      train(model, optimizer, train_dl, val_dl, writer, epochs=3, device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5FMl8caYK2V",
        "outputId": "aa0de9d5-eede-457d-d92f-140c69499a51"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " num_layers = 2, hidden_dim = 200, drop_p = 0.1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0/3]: train accuracy = 2.2677793822367676e-05, validation accuracy = 0.0\n",
            "[1/3]: train accuracy = 0.5653191804885864, validation accuracy = 0.5372605919837952\n",
            "[2/3]: train accuracy = 0.738260805606842, validation accuracy = 0.6921279430389404\n",
            "[3/3]: train accuracy = 0.807630181312561, validation accuracy = 0.7486963272094727\n",
            "\n",
            " num_layers = 2, hidden_dim = 200, drop_p = 0.3\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0/3]: train accuracy = 0.0001920332433655858, validation accuracy = 0.00017654320981819183\n",
            "[1/3]: train accuracy = 0.5293636918067932, validation accuracy = 0.5029727816581726\n",
            "[2/3]: train accuracy = 0.6249050498008728, validation accuracy = 0.5829392075538635\n",
            "[3/3]: train accuracy = 0.6633298993110657, validation accuracy = 0.6109623312950134\n",
            "\n",
            " num_layers = 2, hidden_dim = 400, drop_p = 0.1\n",
            "[0/3]: train accuracy = 0.0, validation accuracy = 0.0\n",
            "[1/3]: train accuracy = 0.7279384732246399, validation accuracy = 0.6916937232017517\n",
            "[2/3]: train accuracy = 0.834759533405304, validation accuracy = 0.775297999382019\n",
            "[3/3]: train accuracy = 0.8833275437355042, validation accuracy = 0.8015109896659851\n",
            "\n",
            " num_layers = 2, hidden_dim = 400, drop_p = 0.3\n",
            "[0/3]: train accuracy = 6.173881411086768e-05, validation accuracy = 2.3602719011250883e-05\n",
            "[1/3]: train accuracy = 0.594819188117981, validation accuracy = 0.5644838809967041\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "writer.close()"
      ],
      "metadata": {
        "id": "V4aytaDdT2wH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Выведем все данные в тензорбод\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir ./runs"
      ],
      "metadata": {
        "id": "iweYkQ9oT3fg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}